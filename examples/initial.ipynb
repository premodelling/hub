{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9d518d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import glob \n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from numpy import array\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f7c236d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=r'C:\\Users\\Joshlin\\Downloads\\infections-master\\infections-master\\warehouse\\design\\raw'\n",
    "\n",
    "data_2 = pd.DataFrame()\n",
    "def read_c(csv):\n",
    "    testing_2 = pd.read_csv(csv)\n",
    "    testing_2['filename'] = os.path.basename(csv).split('.')[0]\n",
    "    return testing_2\n",
    "data_2 = pd.concat(map(read_c, glob.glob(os.path.join(path, \"*.csv\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1955e92e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'covidOccupiedBeds', 'covidOccupiedMVBeds',\n",
       "       'estimatedNewAdmissions', '0-4', '10-14', '15-19', '20-24', '25-29',\n",
       "       '30-34', '35-39', '40-44', '45-49', '5-9', '50-54', '55-59', '60-64',\n",
       "       '65-69', '70-74', '75-79', '80-84', '85-89', '90+', 'dailyCases',\n",
       "       'dailyFirstDoseByVaccinationDate', 'dailySecondDoseByVaccinationDate',\n",
       "       'filename'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data =  data_2\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48bcd508",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9872f50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      20200301\n",
      "1      20200302\n",
      "2      20200303\n",
      "3      20200304\n",
      "4      20200305\n",
      "         ...   \n",
      "657    20211218\n",
      "658    20211219\n",
      "659    20211220\n",
      "660    20211221\n",
      "661    20211222\n",
      "Name: date, Length: 92680, dtype: object\n"
     ]
    }
   ],
   "source": [
    "data['date'] = pd.to_datetime(data['date'],format='%Y-%m-%d')\n",
    " #data =  data[data.date > '2020-12-31']\n",
    "data['date'] = data['date'].astype('str')\n",
    "data['date'] = data['date'].str.replace('-','')\n",
    "print(data['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "217597e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-6.39325676e-01, -5.19152760e-01, -5.76398887e-01, ...,\n",
       "        -4.58394529e-01,  0.00000000e+00, -1.72943639e+00],\n",
       "       [-6.39325676e-01, -5.19152760e-01, -5.76398887e-01, ...,\n",
       "        -4.58394529e-01,  0.00000000e+00, -1.72420360e+00],\n",
       "       [-6.39325676e-01, -5.19152760e-01, -5.76398887e-01, ...,\n",
       "        -4.58394529e-01,  0.00000000e+00, -1.71897081e+00],\n",
       "       ...,\n",
       "       [ 5.74732511e-01,  1.19454245e+00, -5.76398887e-01, ...,\n",
       "        -1.83599762e-01,  1.39000000e+02,  1.71897081e+00],\n",
       "       [ 5.74732511e-01,  1.19454245e+00, -5.76398887e-01, ...,\n",
       "        -1.37659931e-01,  1.39000000e+02,  1.72420360e+00],\n",
       "       [-6.39325676e-01, -5.19152760e-01, -5.76398887e-01, ...,\n",
       "        -9.47730591e-02,  1.39000000e+02,  1.72943639e+00]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "data = data.sort_values(by=['filename','date'])\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "data['new_date'] = (data['date'] - datetime(1970,1,1))\n",
    "data['new_date'] = ( data['new_date'] / np.timedelta64(1, 'D')).astype(int)\n",
    "column_name = ['covidOccupiedBeds','estimatedNewAdmissions','covidOccupiedMVBeds', '0-4', '10-14', '15-19', '20-24', '25-29',\n",
    "       '30-34', '35-39', '40-44', '45-49', '5-9', '50-54', '55-59', '60-64',\n",
    "       '65-69', '70-74', '75-79', '80-84', '85-89', '90+', 'dailyCases',\n",
    "       'dailyFirstDoseByVaccinationDate', 'dailySecondDoseByVaccinationDate','new_date']\n",
    "\n",
    "scaler =StandardScaler()\n",
    "data[column_name]=scaler.fit_transform(data[column_name])\n",
    "le = LabelEncoder()\n",
    "data['filename'] = le.fit_transform(data['filename'])\n",
    "input_data = pd.DataFrame(data.drop('date',axis=1))\n",
    "new_data = input_data\n",
    "n_features = len(new_data.columns)\n",
    "new_data.head()\n",
    "final_data = new_data.values\n",
    "final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2c287304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequences(sequences, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the dataset\n",
    "        if end_ix > len(sequences):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix-1, 2]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4121c9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74139, 7, 27)\n"
     ]
    }
   ],
   "source": [
    "n_steps  = 7\n",
    "X,y = split_sequences(final_data, n_steps)\n",
    "X= np.array(X)\n",
    "y =np.array(y)\n",
    "val_limit = round((len(X)/100)*80)\n",
    "val_2_limit = round((len(X)/100)*10) + val_limit\n",
    "X_train  =  X[:val_limit]\n",
    "y_train  = y[:val_limit]\n",
    "X_val = X[val_limit:val_2_limit]\n",
    "y_val = y[val_limit:val_2_limit]\n",
    "X_test = X[val_2_limit:]\n",
    "y_test = y[val_2_limit:]\n",
    "n_features = X_train.shape[2]\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "67c7ac50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM,GRU,SimpleRNN\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop,SGD\n",
    "from keras import initializers\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1b1b7871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_22 (LSTM)              (None, 7, 50)             15600     \n",
      "                                                                 \n",
      " lstm_23 (LSTM)              (None, 7, 20)             5680      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 7, 1)              21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,301\n",
      "Trainable params: 21,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "initializer = tf.keras.initializers.HeUniform()\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', return_sequences=True,input_shape=(n_steps, n_features),kernel_initializer=initializer))\n",
    "model.add(LSTM(20,activation='relu',return_sequences=True))\n",
    "model.add(Dense(1,'relu'))\n",
    "model.compile(optimizer= Adam(learning_rate= 0.001),loss=tf.keras.losses.MeanSquaredLogarithmicError())\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "77c988a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.0819\n",
      "Epoch 00001: val_loss improved from inf to 0.06390, saving model to weights.h5\n",
      "2317/2317 [==============================] - 21s 8ms/step - loss: 0.0819 - val_loss: 0.0639 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "2312/2317 [============================>.] - ETA: 0s - loss: 0.0630\n",
      "Epoch 00002: val_loss did not improve from 0.06390\n",
      "2317/2317 [==============================] - 18s 8ms/step - loss: 0.0631 - val_loss: 0.0701 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "2310/2317 [============================>.] - ETA: 0s - loss: 0.0582\n",
      "Epoch 00003: val_loss did not improve from 0.06390\n",
      "2317/2317 [==============================] - 18s 8ms/step - loss: 0.0582 - val_loss: 0.0657 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.0563\n",
      "Epoch 00004: val_loss improved from 0.06390 to 0.06164, saving model to weights.h5\n",
      "2317/2317 [==============================] - 18s 8ms/step - loss: 0.0563 - val_loss: 0.0616 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "2311/2317 [============================>.] - ETA: 0s - loss: 0.0550\n",
      "Epoch 00005: val_loss improved from 0.06164 to 0.05904, saving model to weights.h5\n",
      "2317/2317 [==============================] - 17s 8ms/step - loss: 0.0550 - val_loss: 0.0590 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.0541\n",
      "Epoch 00006: val_loss improved from 0.05904 to 0.05862, saving model to weights.h5\n",
      "2317/2317 [==============================] - 16s 7ms/step - loss: 0.0541 - val_loss: 0.0586 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "2311/2317 [============================>.] - ETA: 0s - loss: 0.0535\n",
      "Epoch 00007: val_loss did not improve from 0.05862\n",
      "2317/2317 [==============================] - 17s 7ms/step - loss: 0.0535 - val_loss: 0.0590 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "2309/2317 [============================>.] - ETA: 0s - loss: 0.0530\n",
      "Epoch 00008: val_loss did not improve from 0.05862\n",
      "2317/2317 [==============================] - 40s 17ms/step - loss: 0.0530 - val_loss: 0.0587 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.0525\n",
      "Epoch 00009: val_loss improved from 0.05862 to 0.05848, saving model to weights.h5\n",
      "2317/2317 [==============================] - 18s 8ms/step - loss: 0.0525 - val_loss: 0.0585 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.0521\n",
      "Epoch 00010: val_loss improved from 0.05848 to 0.05810, saving model to weights.h5\n",
      "2317/2317 [==============================] - 18s 8ms/step - loss: 0.0521 - val_loss: 0.0581 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "2312/2317 [============================>.] - ETA: 0s - loss: 0.0519\n",
      "Epoch 00011: val_loss did not improve from 0.05810\n",
      "2317/2317 [==============================] - 18s 8ms/step - loss: 0.0519 - val_loss: 0.0586 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "2312/2317 [============================>.] - ETA: 0s - loss: 0.0516\n",
      "Epoch 00012: val_loss did not improve from 0.05810\n",
      "2317/2317 [==============================] - 19s 8ms/step - loss: 0.0516 - val_loss: 0.0585 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.0515\n",
      "Epoch 00013: val_loss did not improve from 0.05810\n",
      "2317/2317 [==============================] - 19s 8ms/step - loss: 0.0515 - val_loss: 0.0582 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.0515\n",
      "Epoch 00014: val_loss improved from 0.05810 to 0.05800, saving model to weights.h5\n",
      "2317/2317 [==============================] - 18s 8ms/step - loss: 0.0515 - val_loss: 0.0580 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.0512\n",
      "Epoch 00015: val_loss improved from 0.05800 to 0.05751, saving model to weights.h5\n",
      "2317/2317 [==============================] - 19s 8ms/step - loss: 0.0512 - val_loss: 0.0575 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "2313/2317 [============================>.] - ETA: 0s - loss: 0.0511\n",
      "Epoch 00016: val_loss did not improve from 0.05751\n",
      "2317/2317 [==============================] - 18s 8ms/step - loss: 0.0511 - val_loss: 0.0576 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "2313/2317 [============================>.] - ETA: 0s - loss: 0.0510\n",
      "Epoch 00017: val_loss improved from 0.05751 to 0.05720, saving model to weights.h5\n",
      "2317/2317 [==============================] - 19s 8ms/step - loss: 0.0510 - val_loss: 0.0572 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "2312/2317 [============================>.] - ETA: 0s - loss: 0.0508\n",
      "Epoch 00018: val_loss improved from 0.05720 to 0.05681, saving model to weights.h5\n",
      "2317/2317 [==============================] - 18s 8ms/step - loss: 0.0508 - val_loss: 0.0568 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "2314/2317 [============================>.] - ETA: 0s - loss: 0.0508\n",
      "Epoch 00019: val_loss improved from 0.05681 to 0.05634, saving model to weights.h5\n",
      "2317/2317 [==============================] - 18s 8ms/step - loss: 0.0508 - val_loss: 0.0563 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "2313/2317 [============================>.] - ETA: 0s - loss: 0.0507\n",
      "Epoch 00020: val_loss improved from 0.05634 to 0.05603, saving model to weights.h5\n",
      "2317/2317 [==============================] - 18s 8ms/step - loss: 0.0507 - val_loss: 0.0560 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "2314/2317 [============================>.] - ETA: 0s - loss: 0.0505\n",
      "Epoch 00021: val_loss improved from 0.05603 to 0.05578, saving model to weights.h5\n",
      "2317/2317 [==============================] - 19s 8ms/step - loss: 0.0505 - val_loss: 0.0558 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.0506\n",
      "Epoch 00022: val_loss improved from 0.05578 to 0.05562, saving model to weights.h5\n",
      "2317/2317 [==============================] - 18s 8ms/step - loss: 0.0506 - val_loss: 0.0556 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "2312/2317 [============================>.] - ETA: 0s - loss: 0.0503\n",
      "Epoch 00023: val_loss improved from 0.05562 to 0.05489, saving model to weights.h5\n",
      "2317/2317 [==============================] - 18s 8ms/step - loss: 0.0503 - val_loss: 0.0549 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.0502\n",
      "Epoch 00024: val_loss improved from 0.05489 to 0.05459, saving model to weights.h5\n",
      "2317/2317 [==============================] - 22s 9ms/step - loss: 0.0502 - val_loss: 0.0546 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.0503\n",
      "Epoch 00025: val_loss did not improve from 0.05459\n",
      "2317/2317 [==============================] - 23s 10ms/step - loss: 0.0503 - val_loss: 0.0548 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.0500\n",
      "Epoch 00026: val_loss did not improve from 0.05459\n",
      "2317/2317 [==============================] - 21s 9ms/step - loss: 0.0500 - val_loss: 0.0549 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.0501\n",
      "Epoch 00027: val_loss did not improve from 0.05459\n",
      "2317/2317 [==============================] - 20s 8ms/step - loss: 0.0501 - val_loss: 0.0551 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.0499\n",
      "Epoch 00028: val_loss did not improve from 0.05459\n",
      "2317/2317 [==============================] - 21s 9ms/step - loss: 0.0499 - val_loss: 0.0549 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "2314/2317 [============================>.] - ETA: 0s - loss: 0.0497\n",
      "Epoch 00029: val_loss did not improve from 0.05459\n",
      "2317/2317 [==============================] - 20s 9ms/step - loss: 0.0497 - val_loss: 0.0551 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "2311/2317 [============================>.] - ETA: 0s - loss: 0.0500- ETA\n",
      "Epoch 00030: val_loss did not improve from 0.05459\n",
      "2317/2317 [==============================] - 18s 8ms/step - loss: 0.0500 - val_loss: 0.0547 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.0500\n",
      "Epoch 00031: val_loss did not improve from 0.05459\n",
      "2317/2317 [==============================] - 19s 8ms/step - loss: 0.0500 - val_loss: 0.0554 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.0497\n",
      "Epoch 00032: val_loss did not improve from 0.05459\n",
      "2317/2317 [==============================] - 24s 10ms/step - loss: 0.0497 - val_loss: 0.0554 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.0499\n",
      "Epoch 00033: val_loss did not improve from 0.05459\n",
      "2317/2317 [==============================] - 34s 15ms/step - loss: 0.0499 - val_loss: 0.0548 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.0495\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.05459\n",
      "2317/2317 [==============================] - 35s 15ms/step - loss: 0.0495 - val_loss: 0.0549 - lr: 0.0010\n",
      "Epoch 00034: early stopping\n",
      "Wall time: 11min 37s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f12bcec4c0>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "#X_train = X_train.astype('float32')\n",
    "#X_train = \n",
    "#y_train = np.asarray(y_train).astype('float32')\n",
    "#X_val = np.asarray(X_val).astype('float32')\n",
    "#y_val = np.asarray(y_val).astype('float32')\n",
    "#print(X_train[0])\n",
    "\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', min_delta=1e-10, patience=10, verbose=1)\n",
    "rlr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, verbose=1)\n",
    "mcp = ModelCheckpoint(filepath='weights.h5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "\n",
    "tb = TensorBoard('logs')\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train,validation_data =(X_val,y_val),callbacks=[es, rlr, mcp, tb],epochs=200,verbose=1,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a3380e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_3 (GRU)                 (None, 7, 40)             8280      \n",
      "                                                                 \n",
      " gru_4 (GRU)                 (None, 7, 30)             6480      \n",
      "                                                                 \n",
      " gru_5 (GRU)                 (None, 7, 10)             1260      \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 7, 1)              11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,031\n",
      "Trainable params: 16,031\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "112/112 [==============================] - 9s 46ms/step - loss: 0.1355 - val_loss: 0.1475\n",
      "Epoch 2/25\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1312 - val_loss: 0.1377\n",
      "Epoch 3/25\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1245 - val_loss: 0.1313\n",
      "Epoch 4/25\n",
      "112/112 [==============================] - 4s 39ms/step - loss: 0.1237 - val_loss: 0.1313\n",
      "Epoch 5/25\n",
      "112/112 [==============================] - 4s 38ms/step - loss: 0.1215 - val_loss: 0.1299\n",
      "Epoch 6/25\n",
      "112/112 [==============================] - 4s 40ms/step - loss: 0.1212 - val_loss: 0.1281\n",
      "Epoch 7/25\n",
      "112/112 [==============================] - 4s 40ms/step - loss: 0.1207 - val_loss: 0.1290\n",
      "Epoch 8/25\n",
      "112/112 [==============================] - 4s 39ms/step - loss: 0.1197 - val_loss: 0.1261\n",
      "Epoch 9/25\n",
      "112/112 [==============================] - 4s 39ms/step - loss: 0.1194 - val_loss: 0.1303\n",
      "Epoch 10/25\n",
      "112/112 [==============================] - 4s 39ms/step - loss: 0.1188 - val_loss: 0.1269\n",
      "Epoch 11/25\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1186 - val_loss: 0.1272\n",
      "Epoch 12/25\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1186 - val_loss: 0.1271\n",
      "Epoch 13/25\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1181 - val_loss: 0.1272\n",
      "Epoch 14/25\n",
      "112/112 [==============================] - 5s 43ms/step - loss: 0.1179 - val_loss: 0.1270\n",
      "Epoch 15/25\n",
      "112/112 [==============================] - 4s 39ms/step - loss: 0.1178 - val_loss: 0.1270\n",
      "Epoch 16/25\n",
      "112/112 [==============================] - 6s 50ms/step - loss: 0.1175 - val_loss: 0.1267\n",
      "Epoch 17/25\n",
      "112/112 [==============================] - 6s 50ms/step - loss: 0.1175 - val_loss: 0.1268\n",
      "Epoch 18/25\n",
      "112/112 [==============================] - 5s 44ms/step - loss: 0.1174 - val_loss: 0.1267\n",
      "Epoch 19/25\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1171 - val_loss: 0.1270\n",
      "Epoch 20/25\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1169 - val_loss: 0.1268\n",
      "Epoch 21/25\n",
      "112/112 [==============================] - 5s 43ms/step - loss: 0.1169 - val_loss: 0.1270\n",
      "Epoch 22/25\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1168 - val_loss: 0.1269\n",
      "Epoch 23/25\n",
      "112/112 [==============================] - 5s 45ms/step - loss: 0.1167 - val_loss: 0.1270\n",
      "Epoch 24/25\n",
      "112/112 [==============================] - 5s 47ms/step - loss: 0.1165 - val_loss: 0.1270\n",
      "Epoch 25/25\n",
      "112/112 [==============================] - 5s 48ms/step - loss: 0.1165 - val_loss: 0.1270\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f1135c53d0>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "model_2 = Sequential() \n",
    "model_2.add(GRU(40,return_sequences=True,input_shape=(n_steps, n_features),activation='relu',kernel_initializer=initializer))\n",
    "model_2.add(GRU(30,return_sequences=True, activation='relu'))\n",
    "model_2.add(GRU(10,activation='relu',return_sequences=True))\n",
    "model_2.add(Dense(1,activation='relu'))\n",
    "model_2.summary()\n",
    "model_2.compile(optimizer= Adam(learning_rate= 0.001),loss= tf.keras.losses.MeanSquaredLogarithmicError()) \n",
    "model_2.fit(X_train,y_train,validation_data =(X_val,y_val),epochs=25,verbose=1,shuffle=False,batch_size=662)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "193d2eed",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"conv1d\" (type Conv1D).\n\nNegative dimension size caused by subtracting 2 from 1 for '{{node conv1d/Conv1D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](conv1d/Conv1D/ExpandDims, conv1d/Conv1D/ExpandDims_1)' with input shapes: [?,1,1,26], [1,2,26,64].\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(None, 1, 26), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-2f3d90e5eeec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvolutional\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMaxPooling1D\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConv1D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMaxPooling1D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    528\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 530\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    531\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[0;32m   1937\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1938\u001b[0m     \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1939\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1940\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1941\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"conv1d\" (type Conv1D).\n\nNegative dimension size caused by subtracting 2 from 1 for '{{node conv1d/Conv1D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](conv1d/Conv1D/ExpandDims, conv1d/Conv1D/ExpandDims_1)' with input shapes: [?,1,1,26], [1,2,26,64].\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(None, 1, 26), dtype=float32)"
     ]
    }
   ],
   "source": [
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps, n_features)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(1,activation='relu'))\n",
    "model.compile(optimizer=Adam(learning_rate=0.02), loss='mean_absolute_error')\n",
    "# fit model\n",
    "model.fit(X_train, y_train, epochs=7000, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0150e2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7000\n",
      "112/112 [==============================] - 2s 9ms/step - loss: 2.5221\n",
      "Epoch 2/7000\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 2.5221\n",
      "Epoch 3/7000\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 2.5221\n",
      "Epoch 4/7000\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 2.5221\n",
      "Epoch 5/7000\n",
      "103/112 [==========================>...] - ETA: 0s - loss: 2.4491"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-3accb89a0859>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mmodel_3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMeanSquaredLogarithmicError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# fit model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mmodel_3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m7000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m662\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1214\u001b[0m                 _r=1):\n\u001b[0;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1217\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 910\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    940\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 942\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    943\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3128\u001b[0m       (graph_function,\n\u001b[0;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3130\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1958\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1959\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_3 = Sequential()\n",
    "model_3.add(Dense(200,activation='tanh',kernel_initializer=initializer,input_shape=(n_steps, n_features)))\n",
    "model_3.add(Dense(100,activation='tanh'))\n",
    "model_3.add(Dense(50,activation='tanh'))\n",
    "model_3.add(Dense(1,activation='relu'))\n",
    "model_3.compile(optimizer=Adam(learning_rate=0.001), loss=tf.keras.losses.MeanSquaredLogarithmicError())\n",
    "# fit model\n",
    "model_3.fit(X_train, y_train, epochs=7000, verbose=1,batch_size=662,shuffle=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
